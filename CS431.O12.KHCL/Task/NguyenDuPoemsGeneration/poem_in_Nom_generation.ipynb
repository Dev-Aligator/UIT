{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bGsCP9DZFQ5"
      },
      "source": [
        "While some of the sentences are grammatical, most do not make sense. The model has not learned the meaning of words, but consider:\n",
        "\n",
        "* The model is character-based. When training started, the model did not know how to spell an Vietnamese word, or that words were even a unit of text.\n",
        "\n",
        "* The structure of the output resembles a play—blocks of text generally begin with a speaker name, in all capital letters similar to the dataset.\n",
        "\n",
        "* As demonstrated below, the model is trained on small batches of text (100 characters each), and is still able to generate a longer sequence of text with coherent structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srXC6pLGLwS6"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyKZj3bzf9p"
      },
      "source": [
        "### Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Specify the GPU to be used (assuming you have one)\n",
        "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "    # Set memory growth to avoid allocation issues\n",
        "    tf.config.experimental.set_memory_growth(gpus[0], True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHDoRoc5PKWz"
      },
      "source": [
        "### Download the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pD_55cOxLkAb"
      },
      "outputs": [],
      "source": [
        "path_to_file = tf.keras.utils.get_file('VietnamPoems.txt', 'https://raw.githubusercontent.com/Dev-Aligator/UIT/master/CS431.O12.KHCL/Task/NguyenDuPoemsGeneration/VietnamPoemsDatasets/VietnamPoemsDatasets.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjdCjDuSvX_"
      },
      "source": [
        "### Read the data\n",
        "\n",
        "First, look in the text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aavnuByVymwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9df195e-7255-454c-e82d-3933bf96157f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 170865 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Duhg9NrUymwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab24162-8a54-43d5-915f-226a79239044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Than rằng:\n",
            "Chùa Phổ Cứu trăng dìu gió dặt ngỡ một ngày nên nghĩa trăm năm;\n",
            "Doành Đào Nguyên nước chảy hoa trôi bỗng nửa bước chia đường đôi ngả.\n",
            "Chữ chung tình nghĩ lại ngậm ngùi;\n",
            "Câu vĩnh quyết đọc càng buồn bã.\n",
            "Nhớ hai ả xưa:\n",
            "Tính khí dịu dàng;\n",
            "Hìn\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IlCgQBRVymwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69c96d1-6af5-4eb1-9d85-b003a385fbb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## Process the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6GMlCe3qzaL9"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "kLRE6xpoHAor"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "w5apvBDn9Ind"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbmsf23Bymwe"
      },
      "source": [
        "### The prediction task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UopbsKi88tm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b39d5e-635b-4bd1-b975-b155774e96df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(170865,), dtype=int64, numpy=array([37, 49, 43, ...,  1,  1,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qmxrYDCTy-eL"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cjH5v45-yqqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db54e56-7a72-4c5e-ba76-5febe92a60c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T\n",
            "h\n",
            "a\n",
            "n\n",
            " \n",
            "r\n",
            "ằ\n",
            "n\n",
            "g\n",
            ":\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "C-G2oaTxy6km"
      },
      "outputs": [],
      "source": [
        "seq_length = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BpdjRO2CzOfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91acc262-3875-4c99-b381-8dddd553286d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'T' b'h' b'a' b'n' b' ' b'r' b'\\xe1\\xba\\xb1' b'n' b'g' b':' b'\\n' b'C'\n",
            " b'h' b'\\xc3\\xb9' b'a' b' ' b'P' b'h' b'\\xe1\\xbb\\x95' b' ' b'C'\n",
            " b'\\xe1\\xbb\\xa9' b'u' b' ' b't' b'r' b'\\xc4\\x83' b'n' b'g' b' ' b'd'\n",
            " b'\\xc3\\xac' b'u' b' ' b'g' b'i' b'\\xc3\\xb3' b' ' b'd' b'\\xe1\\xba\\xb7'\n",
            " b't' b' ' b'n' b'g' b'\\xe1\\xbb\\xa1' b' ' b'm' b'\\xe1\\xbb\\x99' b't' b' '\n",
            " b'n' b'g' b'\\xc3\\xa0' b'y' b' ' b'n' b'\\xc3\\xaa' b'n' b' ' b'n' b'g' b'h'\n",
            " b'\\xc4\\xa9' b'a' b' ' b't' b'r' b'\\xc4\\x83' b'm' b' ' b'n' b'\\xc4\\x83'\n",
            " b'm' b';' b'\\n' b'D' b'o' b'\\xc3\\xa0' b'n' b'h' b' ' b'\\xc4\\x90'\n",
            " b'\\xc3\\xa0' b'o' b' ' b'N' b'g' b'u' b'y' b'\\xc3\\xaa' b'n' b' ' b'n'\n",
            " b'\\xc6\\xb0' b'\\xe1\\xbb\\x9b' b'c' b' ' b'c' b'h' b'\\xe1\\xba\\xa3' b'y'], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QO32cMWu4a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6089c0-f1b1-4a7a-e8eb-2724009ce9df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Than r\\xe1\\xba\\xb1ng:\\nCh\\xc3\\xb9a Ph\\xe1\\xbb\\x95 C\\xe1\\xbb\\xa9u tr\\xc4\\x83ng d\\xc3\\xacu gi\\xc3\\xb3 d\\xe1\\xba\\xb7t ng\\xe1\\xbb\\xa1 m\\xe1\\xbb\\x99t ng\\xc3\\xa0y n\\xc3\\xaan ngh\\xc4\\xa9a tr\\xc4\\x83m n\\xc4\\x83m;\\nDo\\xc3\\xa0nh \\xc4\\x90\\xc3\\xa0o Nguy\\xc3\\xaan n\\xc6\\xb0\\xe1\\xbb\\x9bc ch\\xe1\\xba\\xa3y'\n",
            "b' hoa tr\\xc3\\xb4i b\\xe1\\xbb\\x97ng n\\xe1\\xbb\\xada b\\xc6\\xb0\\xe1\\xbb\\x9bc chia \\xc4\\x91\\xc6\\xb0\\xe1\\xbb\\x9dng \\xc4\\x91\\xc3\\xb4i ng\\xe1\\xba\\xa3.\\nCh\\xe1\\xbb\\xaf chung t\\xc3\\xacnh ngh\\xc4\\xa9 l\\xe1\\xba\\xa1i ng\\xe1\\xba\\xadm ng\\xc3\\xb9i;\\nC\\xc3\\xa2u v\\xc4\\xa9nh quy\\xe1\\xba\\xbft \\xc4\\x91\\xe1\\xbb\\x8dc c\\xc3\\xa0n'\n",
            "b'g bu\\xe1\\xbb\\x93n b\\xc3\\xa3.\\nNh\\xe1\\xbb\\x9b hai \\xe1\\xba\\xa3 x\\xc6\\xb0a:\\nT\\xc3\\xadnh kh\\xc3\\xad d\\xe1\\xbb\\x8bu d\\xc3\\xa0ng;\\nH\\xc3\\xacnh dung \\xe1\\xba\\xbbo l\\xe1\\xba\\xa3.\\nR\\xe1\\xba\\xa1ng l\\xc3\\xa0u l\\xc3\\xa0u g\\xc6\\xb0\\xc6\\xa1ng \\xc4\\x91an qu\\xe1\\xba\\xbf v\\xe1\\xbb\\xaba tr\\xc3\\xb2n;\\nNo'\n",
            "b'n m\\xc6\\xa1n m\\xe1\\xbb\\x9fn \\xc4\\x91o\\xc3\\xa1 h\\xe1\\xba\\xa3i \\xc4\\x91\\xc6\\xb0\\xe1\\xbb\\x9dng ch\\xc6\\xb0a n\\xe1\\xbb\\x9f.\\nS\\xe1\\xba\\xafc l\\xc3\\xb4ng m\\xc3\\xa0y, s\\xc4\\x83n m\\xc3\\xb4i s\\xc3\\xa1p ai ch\\xc3\\xaa r\\xe1\\xba\\xb1ng x\\xe1\\xba\\xa5u m\\xc3\\xb4 m\\xe1\\xbb\\x93;\\nTh\\xe1\\xba\\xa5p m\\xc3\\xa0i t\\xc3\\xb3c cao \\xc4\\x91\\xc6\\xb0'\n",
            "b'\\xe1\\xbb\\x9dng ng\\xc3\\xb4i ta kh\\xc3\\xaan \\xc4\\x91\\xc3\\xa3 \\xc4\\x91\\xe1\\xba\\xb9p cha ch\\xe1\\xba\\xa3.\\nTi\\xe1\\xba\\xbfng c\\xc6\\xb0\\xe1\\xbb\\x9di ti\\xe1\\xba\\xbfng n\\xc3\\xb3i nghe c\\xc5\\xa9ng h\\xe1\\xbb\\xafu t\\xc3\\xacnh;\\nN\\xc6\\xb0\\xe1\\xbb\\x9bc b\\xc6\\xb0\\xe1\\xbb\\x9bc n\\xc6\\xb0\\xe1\\xbb\\x9bc \\xc4\\x91i th\\xe1\\xba\\xadt l\\xc3\\xa0 v'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WxbDTJTw5u_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f9aa19-d35e-4501-d1c3-620ceeaf3c5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "B9iKPXkw5xwa"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GNbw-iR0ymwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c349e17-9ded-49fe-a11c-d3adfddffcc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'Than r\\xe1\\xba\\xb1ng:\\nCh\\xc3\\xb9a Ph\\xe1\\xbb\\x95 C\\xe1\\xbb\\xa9u tr\\xc4\\x83ng d\\xc3\\xacu gi\\xc3\\xb3 d\\xe1\\xba\\xb7t ng\\xe1\\xbb\\xa1 m\\xe1\\xbb\\x99t ng\\xc3\\xa0y n\\xc3\\xaan ngh\\xc4\\xa9a tr\\xc4\\x83m n\\xc4\\x83m;\\nDo\\xc3\\xa0nh \\xc4\\x90\\xc3\\xa0o Nguy\\xc3\\xaan n\\xc6\\xb0\\xe1\\xbb\\x9bc ch\\xe1\\xba\\xa3'\n",
            "Target: b'han r\\xe1\\xba\\xb1ng:\\nCh\\xc3\\xb9a Ph\\xe1\\xbb\\x95 C\\xe1\\xbb\\xa9u tr\\xc4\\x83ng d\\xc3\\xacu gi\\xc3\\xb3 d\\xe1\\xba\\xb7t ng\\xe1\\xbb\\xa1 m\\xe1\\xbb\\x99t ng\\xc3\\xa0y n\\xc3\\xaan ngh\\xc4\\xa9a tr\\xc4\\x83m n\\xc4\\x83m;\\nDo\\xc3\\xa0nh \\xc4\\x90\\xc3\\xa0o Nguy\\xc3\\xaan n\\xc6\\xb0\\xe1\\xbb\\x9bc ch\\xe1\\xba\\xa3y'\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdfPmdqzf-R"
      },
      "source": [
        "### Create training batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "p2pGotuNzf-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90487279-020b-4440-9fd5-0189afa34173"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## Build The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wj8HQ2w8z4iO"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "IX58Xj9z47Aw"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubPo0_9Prjb"
      },
      "source": [
        "## Try the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "C-_70kKAPrPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c42a65a-5936-490d-b322-12824a0fd2b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 150) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06a0543-a6eb-4d00-c351-bb75d94054ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  38400     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  153750    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4130454 (15.76 MB)\n",
            "Trainable params: 4130454 (15.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "YqFMUQc_UFgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4467f2-32b1-4a20-9330-e5e3a049e9da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 89,  22, 121,  24,  75, 114,  97,  78,  17,  27,  64,  39,  38,\n",
              "        53, 125, 108,  48,  60, 125,  64, 114, 111, 122,  33,  48,  13,\n",
              "       126,  41,  43, 116, 121,  98,   3,  43,  39,  80,  20, 147,  69,\n",
              "        53,  33,  92,  22,  57,  78,  56, 129, 133,  36,  40, 125,  62,\n",
              "         6, 143, 135,  19, 118,  11, 148,  62,   5,  99, 124,  88, 149,\n",
              "       141,  47, 113, 117, 146,  43,   1,  81,  30,  98, 103,  37, 115,\n",
              "        37, 148,  88,  27,  23,  69, 148,  87,  29, 148, 119,  44, 136,\n",
              "        65, 121, 114,  24,  24,  72, 126, 117,  61])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLtsP3mUhCG"
      },
      "source": [
        "Decode these to see the text predicted by this untrained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xWcFwPwLSo05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8935d254-8543-44cf-b566-5f427e43bad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'hi.\\nC\\xc3\\xa1i \\xc4\\x91\\xc3\\xaam h\\xc3\\xb4m \\xe1\\xba\\xa5y \\xc4\\x91\\xc3\\xaam g\\xc3\\xac,\\nB\\xc3\\xb3ng d\\xc6\\xb0\\xc6\\xa1ng l\\xe1\\xbb\\x93ng b\\xc3\\xb3ng \\xc4\\x91\\xe1\\xbb\\x93 my tr\\xe1\\xba\\xadp tr\\xc3\\xb9ng.\\nCh\\xe1\\xbb\\x93i th\\xc6\\xb0\\xe1\\xbb\\xa3c d\\xc6\\xb0\\xe1\\xbb\\xa3c m\\xc6\\xa1 m\\xc3\\xb2ng th\\xe1\\xbb\\xa5y v\\xc5\\xa9,\\n\\xc4\\x90'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"\\xc4\\x90C\\xe1\\xbb\\x8dE\\xc3\\xa8\\xe1\\xba\\xbf\\xe1\\xba\\xa1\\xc3\\xac:IyVUm\\xe1\\xbb\\x95\\xe1\\xba\\xb3gt\\xe1\\xbb\\x95y\\xe1\\xba\\xbf\\xe1\\xba\\xb9\\xe1\\xbb\\x8fPg3\\xe1\\xbb\\x97Ya\\xe1\\xbb\\x83\\xe1\\xbb\\x8d\\xe1\\xba\\xa2!aV\\xc3\\xb2A\\xe2\\x80\\x9c\\xc3\\x9amP\\xc5\\xa9Cq\\xc3\\xacp\\xe1\\xbb\\x9c\\xe1\\xbb\\xa1SX\\xe1\\xbb\\x95v(\\xe1\\xbb\\xb5\\xe1\\xbb\\xa5?\\xe1\\xbb\\x87.\\xe2\\x80\\x9dv'\\xe1\\xba\\xa3\\xe1\\xbb\\x93\\xc4\\x83\\xe2\\x80\\xa6\\xe1\\xbb\\xb1e\\xe1\\xba\\xbd\\xe1\\xbb\\x85\\xe2\\x80\\x99a\\n\\xc3\\xb3M\\xe1\\xba\\xa2\\xe1\\xba\\xa9T\\xe1\\xbb\\x81T\\xe2\\x80\\x9d\\xc4\\x83ID\\xc3\\x9a\\xe2\\x80\\x9d\\xc4\\x82L\\xe2\\x80\\x9d\\xe1\\xbb\\x89b\\xe1\\xbb\\xa7\\xc3\\x81\\xe1\\xbb\\x8d\\xe1\\xba\\xbfEE\\xc3\\xa1\\xe1\\xbb\\x97\\xe1\\xbb\\x85u\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trpqTWyvk0nr"
      },
      "source": [
        "### Attach an optimizer, and a loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ZOeWdgxNFDXq"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "4HrXTACTdzY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820ddebd-1033-475c-8884-94432a7ec036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 150)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(5.0105696, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "MAJfS5YoFiHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16715f8a-f13b-407c-debb-68afe62efcf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.99013"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeOXriLcymww"
      },
      "source": [
        "Configure the training procedure using the `tf.keras.Model.compile` method. Use `tf.keras.optimizers.Adam` with default arguments and the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieSJdchZggUj"
      },
      "source": [
        "### Configure checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6XBUUavgF56"
      },
      "source": [
        "Use a `tf.keras.callbacks.ModelCheckpoint` to ensure that checkpoints are saved during training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "W6fWTriUZP-n"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ky3F_BhgkTW"
      },
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "UK-hmKjYVoll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab714c4-d18a-4c48-fa82-3be43d6459ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "26/26 [==============================] - 10s 243ms/step - loss: 4.6296\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 3s 109ms/step - loss: 3.2815\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 2.6559\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 3s 86ms/step - loss: 2.3332\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 2s 61ms/step - loss: 2.1941\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 2s 64ms/step - loss: 2.1127\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 2.0574\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 2s 60ms/step - loss: 2.0127\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 2s 60ms/step - loss: 1.9758\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 2s 66ms/step - loss: 1.9463\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 2s 64ms/step - loss: 1.9167\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 2s 64ms/step - loss: 1.8913\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 2s 69ms/step - loss: 1.8713\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 2s 60ms/step - loss: 1.8502\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 2s 63ms/step - loss: 1.8325\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 2s 62ms/step - loss: 1.8112\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 2s 60ms/step - loss: 1.7955\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 2s 61ms/step - loss: 1.7771\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 2s 62ms/step - loss: 1.7572\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 2s 67ms/step - loss: 1.7388\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 2s 61ms/step - loss: 1.7204\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 2s 62ms/step - loss: 1.6969\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 2s 60ms/step - loss: 1.6757\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 2s 61ms/step - loss: 1.6518\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 2s 62ms/step - loss: 1.6292\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 1.6018\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 2s 62ms/step - loss: 1.5735\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 2s 61ms/step - loss: 1.5436\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 1.5088\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 1.4731\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 1.4327\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 1.3922\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 2s 62ms/step - loss: 1.3474\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 2s 60ms/step - loss: 1.2953\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 1.2406\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 1.1808\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 2s 58ms/step - loss: 1.1183\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 1.0466\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 2s 60ms/step - loss: 0.9758\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 0.9004\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 0.8190\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 0.7363\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 0.6589\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 0.5770\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 2s 61ms/step - loss: 0.4995\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 2s 59ms/step - loss: 0.4248\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 2s 60ms/step - loss: 0.3588\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 2s 60ms/step - loss: 0.2969\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 2s 63ms/step - loss: 0.2475\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 2s 60ms/step - loss: 0.2073\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjGz1tDkzf-u"
      },
      "source": [
        "The following makes a single step prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "iSBU1tHmlUSs"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "fqMOuDutnOxK"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9yDoa0G3IgQ"
      },
      "source": [
        "Run it in a loop to generate some text. Looking at the generated text, you'll see the model knows when to capitalize, make paragraphs and imitates a Shakespeare-like writing vocabulary. With the small number of training epochs, it has not yet learned to form coherent sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ST7PSyk9t1mT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e863af4a-46ce-4f36-dd94-fec0defb6317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nàng,\n",
            "Vường sang cứu lạ đông phai,\n",
            "Trăm năm bấn hóặt như đàn, ả đào khó am sáu\n",
            "Cuốn phúc hơn quê ngày Yước vác đã thừa Quang.\n",
            "Kía nhân duyên bác ngày dài gửi tan.\n",
            "Bóng thơ đất thấp cha rùng,\n",
            "Lòng là chắm những song thành Dạch gồn.\n",
            "Sinh rời nhỏ đến ta căm chập chấp nằm nỗi Ngôn xa,\n",
            "Khoen sầu bấy hoái mơ màng,\n",
            "Đem thoa người cũ còn kẻh ngỏ thành.\n",
            "Nghe tiền giả điểm ngôi trời cũng cao.\n",
            "Tháng Ba giữa ngược cho tình,\n",
            "Trước sân lòng đã đa mồng báo tay.\n",
            "Trả thúc da cảo hạnh phốc\n",
            "Em vi vương tóc đĩ chiều dao,\n",
            "Quân trung gương lối quay nghĩ quạn thị\n",
            "Bỗng luồn lay thân cũ dang dào,\n",
            "Bổn dây như cũng có nhàu mình Tiên giang đường,\n",
            "Ngũyệt Một bình địa ba đành đến lòng.\n",
            "Ngỡ lời kẽ ngổ then đàn,\n",
            "Phơi thơi cải có tai đây,\n",
            "Khi vỉ chi có điều xa xoán gian;\n",
            "Em đi rồi thay nhặt thôi hay,\n",
            "thoạt vình như đã nhụy là chân thất\n",
            "Những búc sút vùng cỏ hoa.\n",
            "Nhấp nhuộc vâng kiệm hãy còn sông kiên sương.\n",
            "Riêng từ đây lại còn mưa, từ trời còn nước cánh bồi,\n",
            "Tầm thân nào vị chú hàng,\n",
            "Nghĩ trân gia lại buộc vào được khăng\n",
            "Gửi tham sông đã đắc, là hồng thôi ý trùng,\n",
            "Khát thay đánh được má hồng cho tươi.\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.850693464279175\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Nàng'])\n",
        "result = [next_char]\n",
        "\n",
        "phrase_count = 0\n",
        "while phrase_count <= 30:\n",
        "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "    result.append(next_char)\n",
        "    next_char_str = tf.strings.reduce_join(next_char, axis=-1).numpy().decode('utf-8')\n",
        "    if next_char_str == '\\n':\n",
        "        phrase_count += 1\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "muonK6mbFJPX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}